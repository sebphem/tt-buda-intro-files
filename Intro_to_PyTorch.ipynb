{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to PyTorch\n",
    "\n",
    "The method for making a PyBuda Model that we're going to work with is wrapping a PyTorch model using the pybuda.PyTorchModule() function, as it is the fastest way to get a custom model up and running. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch_model = Some_PyTorchModule_Here()\n",
    "buda_model = pybuda.PyTorchModule(\"direct_pt\", torch_model)\n",
    "output = buda_model.run(input1, input2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which incidentally means that we're going to be doing a lot of PyTorch learning and then only at the very end, we're going to put it on tenstorrent hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = torch.Tensor([1,2,3])\n",
    "tensor_2 = torch.Tensor([4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.dot(tensor_1, tensor_2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_matrix_manual = torch.Tensor([[1,0],[0,1]])\n",
    "i_matrix_command = torch.eye(2)\n",
    "input_2_row_vec = torch.Tensor([[7],[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.matmul(i_matrix_manual,input_2_row_vec))\n",
    "print(torch.matmul(i_matrix_command,input_2_row_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def useful_tensor_functions(input_tensor):\n",
    "    # get the number of features per dimension\n",
    "    shape = input_tensor.shape\n",
    "    print('Tensor shape: ', shape)\n",
    "    # Changes the number of dimensions in the tensor\n",
    "    # if n > 0, that is the number of features per dimension\n",
    "    # if n = -1, it will fill the dimension until it cannot anymore\n",
    "    view = tensor_1.view(1,1,1,1,1,1,1,1,1,-1)\n",
    "    print('view shape: ', view.shape)\n",
    "    print('view: ', view)\n",
    "    # Adds another dimension to the tensor\n",
    "    unsqueezed = tensor_1.unsqueeze(dim=-1)\n",
    "    print('Unsqueezed tensor: ', unsqueezed)\n",
    "    # Removes the outer most dimension from the tensor\n",
    "    squeezed = tensor_1.squeeze(dim=-1)\n",
    "    print('Squeezed tensor: ', squeezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_tensor_functions(tensor_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While it is possible to build your own model from pytorch functions, it is much easier to make a child instance of the torch.nn.Module class\n",
    "class ExampleMNISTModel(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        # There's two methods to building the feed forward aspect of your model, this definition is using a more sequential approach\n",
    "        super().__init__()\n",
    "        self.debug = False\n",
    "        # All of the hidden layers in the network\n",
    "        # This command essentially makes a 100x784 matrix under the hood, initialized with random values. This is a lot more useful than making the matrix yourself, as pytorch will handle backpropogation for you\n",
    "        self.l1 = nn.Linear(784, 100)\n",
    "        self.bn_1 = nn.BatchNorm1d(100)\n",
    "        self.l2 = nn.Linear(100, 50)\n",
    "        self.bn_2 = nn.BatchNorm1d(50)\n",
    "        self.l3 = nn.Linear(50, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        # Non linear activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        # Normalization is useful for multiple reasons:\n",
    "        #  - improves accuracy\n",
    "        #  - reduces the impact of outliers in the dataset\n",
    "        \n",
    "    def forward(self, input: torch.Tensor, batch_size: int):\n",
    "        # Easier to understand for people coming from non-ML backgrounds\n",
    "        if not self.debug:\n",
    "            input = input.view(batch_size,-1)\n",
    "            x = self.l1(input)\n",
    "            x = self.bn_1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.l2(x)\n",
    "            x = self.bn_2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.l3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.softmax(x)\n",
    "            return x\n",
    "        else:\n",
    "            input = input.view(batch_size,-1)\n",
    "            print('pre l1: ', input.shape)\n",
    "            x = self.l1(input)\n",
    "            print('l1: ', x.shape)\n",
    "            x = self.bn_1(x)\n",
    "            print('bn1: ', x.shape)\n",
    "            x = self.relu(x)\n",
    "            print('relu: ', x.shape)\n",
    "            x = self.l2(x)\n",
    "            print('l2: ', x.shape)\n",
    "            x = self.bn_2(x)\n",
    "            print('bn2: ', x.shape)\n",
    "            x = self.relu(x)\n",
    "            print('relu: ', x.shape)\n",
    "            x = self.l3(x)\n",
    "            print('l3: ', x.shape)\n",
    "            x = self.relu(x)\n",
    "            print('relu: ', x.shape)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The less intuitive, more succinct method. Either model will work.\n",
    "class ExampleMNISTModel_2(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.main = torch.nn.Sequential(\n",
    "            nn.Linear(784, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.Linear(50, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input: torch.Tensor, batch_size: int):\n",
    "        input = input.view(batch_size,1,-1)\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we definne an instance of our model that we built above, loss function for telling our model how wrong it was, as well as our optimizer function to perform backwards propagation on the model based on the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1E-4\n",
    "model = ExampleMNISTModel()\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1E-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one line of code can speed up training of your model by A LOT (assuming that you have a CUDA compatible card). When I was training GANs, it wasn't uncommon to see an 8x speedup on the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "Here we're going to be defining and playing around with all of the data that we're going to be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size = train_batch_size, shuffle=True)\n",
    "train_iter = iter(train_loader)\n",
    "data, target = next(train_iter)\n",
    "\n",
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def get_last(iterable):\n",
    "    functools.reduce(lambda _, x : x, iterable)\n",
    "\n",
    "data, target = get_last(train_iter)\n",
    "\n",
    "print('Because we chose a batch size that the dataset isnt a common factor of, we get the following shapes for the last batch of data: ')\n",
    "print('data.shape: ', data.shape)\n",
    "print('target.shape: ', target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the loaders that we will be using for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size = train_batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "test_batch_size = 1000\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(test_dataset, batch_size = test_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for visualizing training\n",
    "\n",
    "I've defined a couple of helper functions in [utils/graph_viz.py](./utils/graph_viz.py). If you would like to look more into them, you're more than welcome to. However, it is not necessary to learning how to build models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.graph_viz import graph_loss, make_confusion_matrix_given_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The most basic training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model into training mode\n",
    "model.train()\n",
    "training_loss = []\n",
    "\n",
    "# purely for timing\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# loop through all of the epochs\n",
    "for epoch in range(1,epochs+1):\n",
    "    print('Epoch #',epoch)\n",
    "    num_samples = len(train_loader.dataset)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # sometimes our batch size doesn't exactly match up to the size of the dataset, so we can either skip the last batch or make the last batch smaller\n",
    "        batch_size = data.size(0)\n",
    "        # Option 1: skip as defined below. Option 2: is to pass the batch size into the model\n",
    "        # if batch_size != train_batch_size:\n",
    "        #     continue\n",
    "        \n",
    "        # resets all of the gradients of the weights inside of the model\n",
    "        # as a rule of thumb, if you forget to do this, the model will never get beyond 50% accuracy\n",
    "        # the gradients for the model will accumulate to be the most average  \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # this is where all of the magic happens\n",
    "        output = model(data, batch_size)\n",
    "        \n",
    "        # print('output shape: ', output.shape)\n",
    "        # print('target shape: ', target.shape)\n",
    "        \n",
    "        # the difference between what we the predicted output would be and the actual value\n",
    "        loss = loss_func(output, target)\n",
    "        \n",
    "        # for seeing whats going on inside of the model\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        \n",
    "        # take one step, in the size of the learning rate towards a lower loss function\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss /= num_samples\n",
    "    print('Training Loss: ', epoch_loss)\n",
    "    training_loss.append(epoch_loss)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(f'Training Took {total_time:.1f} seconds')\n",
    "\n",
    "# set the model into eval mode, making the model run faster, as we don't restructure the data locality around back propagation weights\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_matrix_given_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_loss(**{\"Training Loss\": training_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save your progress\n",
    "from models.MNIST import save_preheated_mnist\n",
    "save_preheated_mnist(model, save_file_int=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extentions that we don't have time to talk about, but are cool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to use our classifier model to generate an image\n",
    "\n",
    "I will assume that one of you will have the question of \"now that we have a network that can understand the difference between two different numbers, can we use it backwards? Can we give the output of the network a number and it'll find its way backwards to do it?\"\n",
    "\n",
    "> Technically Yes, but it will take 1/100th of the time to simply draw out the hand written digit. By the time you read this and understand what I'm saying, you could've written a good 6 digits by hand.\n",
    "\n",
    "The actual way to do this is to use some generative model such as a GAN, or stable diffusion (or more that I don't know about)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.MNIST_no_normalization import load_preheated_mnist\n",
    "from utils.animate import animate_generative_mnist\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "tensor_to_PIL = torchvision.transforms.ToPILImage()\n",
    "PIL_to_tensor = torchvision.transforms.ToTensor()\n",
    "model = load_preheated_mnist()\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_image = torch.zeros((1,28,28))\n",
    "white_image = torch.ones((1,28,28))\n",
    "desired_number = torch.Tensor([8]).long()\n",
    "\n",
    "print('black image: ')\n",
    "display(tensor_to_PIL(black_image))\n",
    "print('white image: ')\n",
    "display(tensor_to_PIL(white_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell pytorch that we actually want it to calculate a gradient on the input\n",
    "black_image.requires_grad = True\n",
    "white_image.requires_grad = True\n",
    "\n",
    "\n",
    "output = model(black_image,batch_size=1)\n",
    "print('Predictions for the Black Image')\n",
    "print('output: ', output)\n",
    "print('desired number: ', desired_number)\n",
    "loss = loss_func(output, desired_number)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('gradient of the black image: ')\n",
    "display(tensor_to_PIL(black_image.grad))\n",
    "\n",
    "adjustment = 0.05 * black_image.grad \n",
    "black_image.requires_grad = False\n",
    "\n",
    "black_image += adjustment\n",
    "\n",
    "print('More \"8\" like black image: ')\n",
    "display(tensor_to_PIL(black_image))\n",
    "\n",
    "\n",
    "output = model(white_image,batch_size=1)\n",
    "print('Predictions for the White Image')\n",
    "print('output: ', output)\n",
    "print('desired number: ', desired_number)\n",
    "loss = loss_func(output, desired_number)\n",
    "loss.backward()\n",
    "\n",
    "print('gradient of the white image: ')\n",
    "display(tensor_to_PIL(white_image.grad))\n",
    "\n",
    "white_image.requires_grad = False\n",
    "white_image += 0.05*white_image.grad \n",
    "\n",
    "print('More \"8\" like white image: ')\n",
    "display(tensor_to_PIL(white_image))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_image = torch.zeros((1,28,28))\n",
    "white_image = torch.ones((1,28,28))\n",
    "desired_number = torch.Tensor([8]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "file_path = str(Path(os.path.abspath('')) / \"black_image.gif\")\n",
    "animate_generative_mnist(model=model, input_tensor=black_image, desired_number=8,delta=0.01, epochs=100, output_filepath=file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
